{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Sequence, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from monai.networks.blocks.convolutions import Convolution, ResidualUnit\n",
    "from monai.networks.layers.factories import Act, Norm\n",
    "from monai.networks.layers.simplelayers import SkipConnection\n",
    "from monai.utils import alias, export\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric, compute_meandice\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.optim as opt\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import h5py\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from monai.networks.nets import UNet\n",
    "from Graph_GNN import UNet_GNN_pass, UNet_GNN_linear\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = []\n",
    "end = []\n",
    "for i in range(625):\n",
    "    if i >= 0 and i <= 24:\n",
    "        if i == 0:\n",
    "            start.append(0)\n",
    "            end.append(1)\n",
    "            start.append(0)\n",
    "            end.append(50)\n",
    "        elif i == 24:\n",
    "            start.append(24)\n",
    "            end.append(23)\n",
    "            start.append(24)\n",
    "            end.append(49)\n",
    "        else:\n",
    "            start.append(i)\n",
    "            end.append(i-1)\n",
    "            start.append(i)\n",
    "            end.append(i+1)\n",
    "            start.append(i)\n",
    "            end.append(i+25)\n",
    "    elif (i >= 600 and i <= 624):\n",
    "        if i == 600:\n",
    "            start.append(600)\n",
    "            end.append(575)\n",
    "            start.append(600)\n",
    "            end.append(601)\n",
    "        elif i == 624:\n",
    "            start.append(600)\n",
    "            end.append(575)\n",
    "            start.append(600)\n",
    "            end.append(601)\n",
    "        else:\n",
    "            start.append(i)\n",
    "            end.append(i-1)\n",
    "            start.append(i)\n",
    "            end.append(i+1)\n",
    "            start.append(i)\n",
    "            end.append(i-25)\n",
    "    elif i % 25 == 0:\n",
    "        start.append(i)\n",
    "        end.append(i+1)\n",
    "        start.append(i)\n",
    "        end.append(i+25)\n",
    "        start.append(i)\n",
    "        end.append(i-25)\n",
    "    elif i % 25 == 24:\n",
    "        start.append(i)\n",
    "        end.append(i-1)\n",
    "        start.append(i)\n",
    "        end.append(i+25)\n",
    "        start.append(i)\n",
    "        end.append(i-25)     \n",
    "    else:\n",
    "        start.append(i)\n",
    "        end.append(i-1)\n",
    "        start.append(i)\n",
    "        end.append(i+25)\n",
    "        start.append(i)\n",
    "        end.append(i-25)  \n",
    "        start.append(i)\n",
    "        end.append(i+1)\n",
    "edges = torch.tensor([start, end], dtype=torch.long)\n",
    "    \n",
    "def one_hot(labels: torch.Tensor, num_classes: int, dtype: torch.dtype = torch.float, dim: int = 1) -> torch.Tensor:\n",
    "    # if `dim` is bigger, add singleton dim at the end\n",
    "    if labels.ndim < dim + 1:\n",
    "        shape = list(labels.shape) + [1] * (dim + 1 - len(labels.shape))\n",
    "        labels = torch.reshape(labels, shape)\n",
    "\n",
    "    sh = list(labels.shape)\n",
    "\n",
    "    if sh[dim] != 1:\n",
    "        raise AssertionError(\"labels should have a channel with length equal to one.\")\n",
    "\n",
    "    sh[dim] = num_classes\n",
    "\n",
    "    o = torch.zeros(size=sh, dtype=dtype, device=labels.device)\n",
    "    labels = o.scatter_(dim=dim, index=labels.long(), value=1)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './'\n",
    "data_path = [base + 'val/' + x for x in os.listdir(base + 'val/')]\n",
    "names = [x.split('/')[-1].split('_')[0] for x in data_path]\n",
    "counts = pd.Series(names).value_counts().to_dict()\n",
    "templete =  './val/{x}_{y}.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_one_case(name, counts, model, device, unet=False):\n",
    "    count = counts[name]\n",
    "    real = []\n",
    "    out = []\n",
    "    inp = []\n",
    "    for i in range(1, count-2):\n",
    "        paths = []\n",
    "        for j in range(i-1, i+2):\n",
    "            paths.append(templete.format(x=name, y=j))\n",
    "        xs = []\n",
    "        f = h5py.File(paths[1], 'r')\n",
    "        y = f['gt'][:]\n",
    "        real.append(y)\n",
    "        inp.append(f['ct'][:])\n",
    "        f.close()\n",
    "        for path in paths:\n",
    "            f = h5py.File(path, 'r')\n",
    "            x = f['ct'][:].astype(np.float)\n",
    "            x = torch.from_numpy(x)\n",
    "            x = x.float().view(1, 400, 400)\n",
    "            xs.append(x)  \n",
    "            f.close()\n",
    "        x = torch.cat(xs, dim=0).view(1, 3, 400, 400)\n",
    "        x = x.to(device)\n",
    "        if unet:\n",
    "            outputs = model(x)\n",
    "        else:\n",
    "            outputs = model(x, device, edges)\n",
    "        outputs = torch.nn.functional.softmax(outputs, 1)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.view(400, 400).detach().cpu().numpy()\n",
    "        out.append(predicted)\n",
    "        \n",
    "    out = np.array(out)\n",
    "    real = np.array(real)\n",
    "    inp = np.array(inp)\n",
    "    \n",
    "    out = np.uint8(out)\n",
    "    real = np.uint8(real)\n",
    "    \n",
    "    print(out.shape, inp.shape, real.shape)\n",
    "    \n",
    "    \n",
    "    return inp, real, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_model(model, device, unet, model_name):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for name in tqdm(counts.keys()):\n",
    "        inp, real, out = save_one_case(name, counts, model, device, unet=unet)\n",
    "        os.makedirs('./3dtestoutput/{x}/'.format(x = name), exist_ok=True)\n",
    "        if model_name=='unet':\n",
    "            img_nii = sitk.GetImageFromArray(inp)\n",
    "            loc =  './3dtestoutput/{x}/'.format(x = name) + 'ct.nii.gz'\n",
    "            sitk.WriteImage(img_nii, loc)\n",
    "            \n",
    "            img_nii = sitk.GetImageFromArray(real)\n",
    "            loc =  './3dtestoutput/{x}/'.format(x = name) + 'grount_truth.nii.gz'\n",
    "            sitk.WriteImage(img_nii, loc) \n",
    "            \n",
    "            img_nii = sitk.GetImageFromArray(out)\n",
    "            loc =  './3dtestoutput/{x}/'.format(x = name) + 'unet.nii.gz'\n",
    "            sitk.WriteImage(img_nii, loc)\n",
    "            \n",
    "        elif model_name=='linear':\n",
    "            img_nii = sitk.GetImageFromArray(out)\n",
    "            loc =  './3dtestoutput/{x}/'.format(x = name) + 'gnn_unet_linear.nii.gz'\n",
    "            sitk.WriteImage(img_nii, loc)    \n",
    "        \n",
    "        else:\n",
    "            img_nii = sitk.GetImageFromArray(out)\n",
    "            loc =  './3dtestoutput/{x}/'.format(x = name) + 'gnn_unet_pass.nii.gz'\n",
    "            sitk.WriteImage(img_nii, loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac13a13d77e49358bbce06cf0e2fc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f01adc88f2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel_unet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model_weights/best_unet_weight.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:7\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_one_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_unet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmodel_unet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-3cd7b4a507e8>\u001b[0m in \u001b[0;36mtest_one_model\u001b[0;34m(model, device, unet, model_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_one_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./3dtestoutput/{x}/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'unet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-9d9b747cf44f>\u001b[0m in \u001b[0;36msave_one_case\u001b[0;34m(name, counts, model, device, unet)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ct'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xinrui/lib/python3.8/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_unet = UNet(\n",
    "    dimensions=2,\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")\n",
    "model_unet.load_state_dict(torch.load('./model_weights/best_unet_weight.pt'))\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_one_model(model_unet, device, True, 'unet')\n",
    "del model_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnn_pass = UNet_GNN_pass(\n",
    "    dimensions=2,\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")\n",
    "model_gnn_pass.load_state_dict(torch.load('./model_weights/best_sage_conv_weight.pt'))\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_one_model(model_gnn_pass, device, False, 'pass')\n",
    "del model_gnn_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnn_linear = UNet_GNN_linear(\n",
    "    dimensions=2,\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")\n",
    "model_gnn_linear.load_state_dict(torch.load('./model_weights/best_sage_conv_linear_weight.pt'))\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "get_stat(model_gnn_linear, device, 'linear')\n",
    "del model_gnn_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xinrui",
   "language": "python",
   "name": "xinrui"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
